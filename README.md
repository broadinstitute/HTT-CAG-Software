# HTT-CAG-Software
Software for analysis of the CAG repeat in Huntington's Disease (HD) using a specialized single-cell RNA sequencing assay.

## Overview

The software processes PacBio CCS (circular consensus sequencing) reads that were generated from a specific library format generated by the single-cell HTT-CAG repeat assay.

The main input is a bam (or cram) file containing the sequenced PacBio reads, aligned to the GRCh38 reference (see details below). In addition to the reads, the software requires other metadata, typically from small text files, describing the snRNA-seq reactions that were sequenced on the flowcell, the indexes used for each reaction, etc.

The software runs in three passes. The first pass processes the reads in the input bam/cram file and emits several tab-delimited output files. The first pass can be parallelized to reduce runtime. The second pass does additional processing the output files from the first pass and emits more text files. The second pass is separated from the first mostly for ease of development. The third pass (written in R) processes the files from the first two passes to gather reads that originate from the same transcript (cell barcode and unique molecular identifier) and performs per-transcript analyses, including estimating the repeat length from the source transcript. The result are tab-delimited text files that are then used for downstream QC and analyses. The first two passes produce "per-read" output; the third pass produces "per-transcript" output.

## Example analysis
A working example is provided in the `example` directory.

By default, the example uses a very small data set, downsampled from a mouse experiment.
The small example will run in under a minute, but the output is not representative of a larger analysis.
In particular, none of the cells pass QC due to the low number of reads.
The small example is intended only to provide an example of the overall workflow.

### Sample data

The sample data for the example is in the `example/data` directory.
This is single-nucleus data from mouse striatum and cortex from a Q111 mouse (also known as an HDhQ111-KI mouse) which is a mouse model for HD.
This mouse model has been genetically altered to contain a (heterozygous) copy of human HTT exon 1 with a repeat length of approximately 111 CAGs.
For information on HD mouse model can be found here:  https://www.jax.org/strain/003598.

To generate the mouse data used here, four 10x reactions were performed, two on mouse striatum and two on mouse cortex, all using the same mouse.
The data was collected when the mouse was approximately 14 months old.

The following files are provided in the `example/data` directory:

```
m64298e_220829_033656.ds3.bam
m64298e_220829_033656.ds3.bam.bai
```
Pacbio reads, which were aligned to the GRCh38 "no alt" reference using the standard PacBio alignment software.
The name of the files (m64298e_220829_033656) is the PacBio movie name from the sequencing run.
To allow the example to run faster, the reads were downsampled 1000x using `samtools view -s 0.001` (indicated here by the ds3 suffix).

```
m64298e_220829_033656.ds3.indexes.txt
```
This file provides the list of reactions on the flowcell.
Each reaction is implicitly numbered (starting from one) and is also given a textual reaction ID.
There are two columns, `PBINDEX1` and `PBINDEX2` that provide the sequences of the Illumina indexes that were used for each reaction.
These index sequences are used for demultiplexing the data from the flowcell.

```
m64298e_220829_033656.ds3.stampfiles.txt
```
This file maps each reaction on the flowcell to a file that contains a list of "STAMPs", which are cell barcodes that have passed QC.
There is one stamp file for each 10x reaction. The list of STAMPs is output from an analysis pipeline run on the standard 10x library.

```
PacBio_080322_Q111mouse_9526_ST_CTX_rxn1.selectedCellBarcodes.txt
PacBio_080322_Q111mouse_9526_ST_CTX_rxn2.selectedCellBarcodes.txt
PacBio_080322_Q111mouse_9526_ST_CTX_rxn3.selectedCellBarcodes.txt
PacBio_080322_Q111mouse_9526_ST_CTX_rxn4.selectedCellBarcodes.txt
```
The STAMP files for each of the reactions on the example flowcell.

### Example analysis script

The code for the example is in the `example/scripts` directory.
See prerequisites below before running the example.

The example analysis script must be run from the `example` directory for the relative references to work correctly.

```
$ cd example
$ scripts/run_example_analysis.sh
```
### Prerequisites

#### Required software

R (version 4+)

Java 1.8 (for Genome STRiP)

ant (for building)

Genome STRiP (SVToolkit), r2041 or higher
https://software.broadinstitute.org/software/genomestrip/

Genome STRiP should be downloaded automatically during the build process.

#### Building the library

The software components are currently built using ant. Once ant is installed, you can build the release (jar, scripts, etc.) using

```
$ ant
```

#### Reference sequence

Before the example code can be run, you need to have a local copy of a GRCh38 reference genome, which is not provided.

By default, the script will attempt to download a reference sequence from NCBI and cache it locally in the `reference` directory.
Alternatively, you can modify the script `scripts/run_example_analysis.sh` to supply a local copy of the reference genome.
The reference file must be unzipped and indexed using `samtools faidx`.

Technically, the reference file should be the GRCh38 "no alt" fasta file which was used to align the pacbio data.
In practice, any GRCh38 reference sequence will work, including one with alt contigs and decoy sequences, so long as the primary chr1 sequence is the same as GRCh38.

Note that although the data used in this example is Q111 mouse, this mouse model has a human HTT exon 1 and the PacBio reads were aligned to a human hg38 reference.

The HTT analysis code currently requires alignment to a GRCh38 compatible reference. Changes to the code would be necessary to use any other reference genone.

## Output file formats

The main output of this analysis pipeline is the UMI summary file `out/filtered2/m64298e_220829_033656.ds3.t=10.umi_summary.txt`.

UMI summary files are tab-delimited files with the following columns:

<dl>
  <dt>RXN</dt>
  <dd>Reaction index from 1 to N</dd>
  <dt>RXNID</dt>
  <dd>User supplied name for this reaction.</dd>
  <dt>RAWUMI</dt>
  <dd>The decoded UMI sequence as it appeared in the input reads.</dd>
  <dt>UMI</dt>
  <dd>UMI reformatted to match the format used in transcriptome analysis (CBC.UMI)</dd>
  <dt>UMISOURCE</dt>
  <dd>Either "S" if this UMI is a stamp (from user supplied list) or "T" if based on read threshold or both ("S,T").</dd>
  <dt>NREADS</dt>
  <dd>The number of reads assigned to this UMI during the consensus process.</dd>
  <dt>READLENGTH</dt>
  <dd>The median read length of reads assigned to this UMI.</dd>
  <dt>RXNN</dt>
  <dd>The number of reads used to infer the reaction.</dd>
  <dt>CATEGORY</dt>
  <dd>One of several fixed categories describing characteristics of the transcript.</dd>
  <dt>CATEGORYN</dt>
  <dd>The number of reads used to infer CATEGORY.</dd>
  <dt>REPLENGTH</dt>
  <dd>The consensus CAG repeat length in repeat units.
      This value may be non-integer, but it is typical to round to the nearest integer for downstream analysis.
      The consensus CAG repeat length is the half-sample mode of the estimated repeat length in each read.
  </dd>
  <dt>REPLENGTHN</dt>
  <dd>The number of reads used to infer REPLENGTH.</dd>
  <dt>REPUNITS</dt>
  <dd>Experimental. Not fully implemented. Do not use. Use REPLENGTH for the repeat length.</dd>
  <dt>REPHASCAA</dt>
  <dd>Does this UMI contain a terminal "CAACAG" sequence? (T or F)</dd>
  <dt>ALIGNSTART</dt>
  <dd>The median alignment start position of the reads assigned to this UMI.</dd>
  <dt>ALIGNEND</dt>
  <dd>The median alignment end position of the reads assigned to this UMI.</dd>
  <dt>ALIGNN</dt>
  <dd>The number of reads used to infer ALIGNSTART and ALIGNEND.</dd>
  <dt>POLYALEN</dt>
  <dd>The median length of the polyA sequence at the end of the reads.</dd>
  <dt>MINDIST</dt>
  <dd>The minimum Levenshtein distance between this UMI and the next closest UMI in this UMI's reaction.</dd>
  <dt>OUTLEFT</dt>
  <dd>The fraction of "left outlier" reads in this UMI's CAG repeat length distribution.
      Left outliers are reads with a repeat length less than REPLENGTH - 2*sqrt(REPLENGTH).
  </dd>
  <dt>OUTRIGHT</dt>
  <dd>The fraction of "right outlier" reads in this UMI's CAG repeat length distribution.
      Right outliers are reads with a repeat length greater than REPLENGTH + 2*sqrt(REPLENGTH).
</dl>

There are also UMI summary files in two other directories in the example output.

The `qc` directory contains output that does not use stamps and has slightly less stringent filtering. This may be useful for downstream analysis before the transcriptome data is available or for comparison with more stringent filtering.

The `filtered` directory is the same as the `filtered2` directory, except that the filtered2 directory uses the stamp files to assign reactions to reads if they could not be reliably inferred from the indexes embedded in the reads.

## Scaling up

In the `example/data` directory, we include both a downsampled bam file and the bam file for the full flowcell for the same mouse data.
If you want to run the full flowcell, pass the argument use

```
$ cd example
$ scripts/run_example_analysis.sh full
```

Note that unlike the downsampled bam, this analysis may take 5 or 6 hours if the processing is not parallelized.
It will, however, produce more realistic and useful output. The downsampled bam produces no UMIs that pass the default quality thresholds.

When running a full analysis, it can be useful to parallelize the first decoding step (PBSCHTTAnalyzer). This first pass processes each input read separately. The software has some built-in features to make it easy to do simple parallel processing on the reads from a single flowcell, for example on a compute cluster or on the cloud.

PBSCHTTAnalyzer supports an argument `-scatter k@N` which says that the input should be sharded into N equal-sized partitions (logically, not physically), which are numbered from 1 to N, and this invocation should process partition k. Each parallel process reads the entire input file, but the I/O burden is not large for reasonable values of N. The caller is responsible for naming the output files so they do not clash (typically by including k in the output file name).

The example script contains some template code to do the parallelization, although you will have to adapt it to run in your environment.
In particular, the script `run_queue_scatter.sh` (not supplied) is specific to our local environment and scatters multiple jobs on the local compute cluster (based on the first argument) , then waits for all scattered jobs to complete before returning. The script `pb_analyze_flowcell_decode_gather.sh` can be used to gather the resulting output. In practice, we use this approach to scatter the processing of each flowcell across 10 parallel jobs, plus of course each flowcell can be processed in parallel.
